{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выглядит красиво\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import hstack\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# буду исследовать.\n",
    "# я не делил на test и train, довольствуясь кроссвалидацией. на момент 20 апреля я считаю, что так делать можно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# соединил всё в кучу, чтобы сразу все данные привести в нули и единицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([data, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  target\n",
       "0     NaN      NaN  Our Deeds are the Reason of this #earthquake M...     1.0\n",
       "1     NaN      NaN             Forest fire near La Ronge Sask. Canada     1.0\n",
       "2     NaN      NaN  All residents asked to 'shelter in place' are ...     1.0\n",
       "3     NaN      NaN  13,000 people receive #wildfires evacuation or...     1.0\n",
       "4     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...     1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_data.reset_index()\n",
    "all_data.drop('index', axis=1, inplace=True)\n",
    "all_data.drop('id', axis=1, inplace=True)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5703402075397347"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4342 / (len(data))\n",
    "# если данные случайно брались для теста, тогда надо получить accuracy выше этого числа, иначе классификатор - бесполезен.\n",
    "# но мне кажется, что в тесте много единичек, судя по score на kaggle. Он сильно вырос по сравнению с кроссвалидацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['engulfed', 'evacuation', 'sandstorm', 'avalanche', 'rescuers', 'razed']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(all_data[all_data.keyword.notna()].keyword))[:6]\n",
    "# надо убрать много окончаний при помощи Stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body%20bags              50\n",
       "burning%20buildings      50\n",
       "fatal                    50\n",
       "rubble                   50\n",
       "suicide%20bomb           50\n",
       "                         ..\n",
       "forest%20fire            24\n",
       "threat                   16\n",
       "inundation               14\n",
       "radiation%20emergency    14\n",
       "epicentre                13\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[all_data.keyword.notna()].keyword.value_counts()\n",
    "# нет совсем малочисленных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA                               141\n",
       "New York                          109\n",
       "United States                      65\n",
       "London                             58\n",
       "Canada                             42\n",
       "                                 ... \n",
       "Madrid, Comunidad de Madrid         1\n",
       "ÌÏT: 36.142163,-95.979189           1\n",
       "Southeast Michigan (HOTH)           1\n",
       "Leeds, England, United Kingdom      1\n",
       "KADUNA, NIGERIA                     1\n",
       "Name: location, Length: 4521, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[all_data.location.notna()].location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# большинство значений придётся удалить (более 90%), потому что они бесполезны в таком виде из-за уникальности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_data[all_data.location.notna()].location.value_counts() > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer= PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_stop_words_and_punct(string):\n",
    "    new_string = []\n",
    "    for i in string.split():\n",
    "        if i not in ENGLISH_STOP_WORDS and 'http' not in i:\n",
    "            new_string.append(i)\n",
    "    new_string = ' '.join(new_string)\n",
    "    new_string = re.sub(r'\\d+', '', new_string)\n",
    "    new_string = re.sub(r'[^\\w\\s]','', new_string)\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edit = all_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edit['text'] = data_edit['text'].apply(lambda x: stemmer.stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edit['text'] = data_edit['text'].apply(lambda x: del_stop_words_and_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edit.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds reason earthquake allah forgive al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent photo ruby alaska smoke wildfire...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text\n",
       "0     NaN      NaN           deeds reason earthquake allah forgive al\n",
       "1     NaN      NaN                   forest near la ronge sask canada\n",
       "2     NaN      NaN  residents asked shelter place notified officer...\n",
       "3     NaN      NaN   people receive wildfires evacuation orders ca...\n",
       "4     NaN      NaN  just got sent photo ruby alaska smoke wildfire..."
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_edit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_label = []\n",
    "for i in data_edit[data_edit.target.notna()].text:\n",
    "    words_label.extend(i.split())\n",
    "words_label = set(words_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17391"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_wolabel = []\n",
    "for i in data_edit[data_edit.target.isna()].text:\n",
    "    words_wolabel.extend(i.split())\n",
    "words_wolabel = set(words_wolabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10256"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_wolabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4520"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unused_words = words_wolabel - words_label\n",
    "len(unused_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# потеряем 4520 слов, потому что они не участвуют в обучении модели. Слова эти довольно редкие, либо бессмысленные. Довольно много(("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_one = data_edit['location'].value_counts() > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edit.loc[:, ['keyword', 'location']] = data_edit.loc[:, ['keyword', 'location']].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edit.loc[:, 'location'] = data_edit.loc[:, 'location'].apply(lambda x: 'Unknown' if more_than_one[x] == False else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown                           7431\n",
       "USA                                141\n",
       "New York                           109\n",
       "United States                       65\n",
       "London                              58\n",
       "                                  ... \n",
       "Jakarta, Indonesia                   2\n",
       "London                               2\n",
       "Bukittinggi  ?? Sumatera Barat       2\n",
       "The Jewfnited State                  2\n",
       "Dorset, UK                           2\n",
       "Name: location, Length: 730, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_edit.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_unused_words(x):\n",
    "    new_x = []\n",
    "    for i in x.split():\n",
    "        if i not in unused_words:\n",
    "            new_x.append(i)\n",
    "    return ' '.join(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_edit[data_edit['target'].isna()].index:\n",
    "    data_edit.loc[i, 'text'] = delete_unused_words(data_edit.loc[i, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [keyword, location, text, target]\n",
       "Index: []"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_edit[data_edit.text.isna()]\n",
    "#нет na после этой операции, к счастью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убрать аналогично location и keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_location = set(data_edit[data_edit['target'].isna()]['location']) - set(data_edit[data_edit['target'].notna()]['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_edit[data_edit['target'].isna()].index:\n",
    "    if data_edit.loc[i, 'location'] in delete_location:\n",
    "        data_edit.loc[i, 'location'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data_edit[data_edit['target'].isna()]['location']) - set(data_edit[data_edit['target'].notna()]['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data_edit[data_edit['target'].notna()]['keyword']) - set(data_edit[data_edit['target'].isna()]['keyword'])\n",
    "# пусто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь идём к моделям через pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_col = ['keyword', 'location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "    ('text', CountVectorizer(), 'text'),\n",
    "    ('cat', OneHotEncoder(handle_unknown=\"ignore\"), code_col)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_prep = full_pipeline.fit_transform(data_edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_prep = full_data_prep[:len(y), :]\n",
    "answer_prep = full_data_prep[len(y):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier()\n",
    "rnf_clf = RandomForestClassifier()\n",
    "ext_clf = ExtraTreesClassifier()\n",
    "svc_clf = SVC()\n",
    "mlp_clf = MLPClassifier()\n",
    "logic_clf = LogisticRegression()\n",
    "estimators = [sgd_clf, rnf_clf, ext_clf, svc_clf, mlp_clf, logic_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier 0.6356267412595136\n",
      "RandomForestClassifier 0.6218360953336617\n",
      "ExtraTreesClassifier 0.6147426710716021\n",
      "SVC 0.6637433207679359\n",
      "MLPClassifier 0.6156631173517237\n",
      "LogisticRegression 0.6561215976145014\n"
     ]
    }
   ],
   "source": [
    "for est in estimators:\n",
    "    print(est.__class__.__name__, np.mean(cross_val_score(est, full_train_prep, y, scoring='accuracy', cv=5, verbose=0)))\n",
    "# самое простое оказывается достаточно эффективным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# далее я подкручиваю параметры... Некоторые клетки удалял."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_svc = {'kernel': ['poly', 'rbf', 'sigmoid'], 'C':[1, 5, 15, 50], 'degree':[3, 4, 5, 6]}\n",
    "grid_svc = GridSearchCV(svc_clf, params_svc, scoring='accuracy', cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_svc.fit(full_train_prep, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'degree': 3, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6621642049244049"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf = SVC(**grid_svc.best_params_, probability=True)\n",
    "np.mean(cross_val_score(svc_clf, full_train_prep, y, scoring='accuracy', cv=5, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(svc_clf)\n",
    "# пытаюсь бустинг прикрутить к svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5744100748660703"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(ada_clf, full_train_prep, y, scoring='accuracy', cv=5, verbose=0))\n",
    "# за это время (часа 3) я успел уже нарисовать 2 рисунка с ромашками. А результат не очень. Возможно я какую-то ерунду сделал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_log = {'penalty':['l2'],\n",
    "             'C':[0.02, 0.05, 0.08, 0.1, 0.12, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "             'solver':['saga']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_log = GridSearchCV(logic_clf, params_log, scoring='accuracy', cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_log.fit(full_train_prep, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6999923071817893"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_log.best_score_\n",
    "# его надо постараться улучшить на кроссвалидации. Что впоследствии я не смог сделать и оставил этот классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ниже моя попытка сделать stacking моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnf_clf = RandomForestClassifier(bootstrap=True, min_samples_leaf=2, n_estimators=128)\n",
    "ext_clf = ExtraTreesClassifier(bootstrap=True, min_samples_leaf=2, n_estimators=128)\n",
    "svc_clf = SVC(**grid_svc.best_params_, probability=True)\n",
    "logic_clf = LogisticRegression(solver='saga', penalty='l2', C=0.2, max_iter=500)\n",
    "estimators = [rnf_clf, ext_clf, svc_clf, logic_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_y_pred = []\n",
    "for est in estimators:\n",
    "    est.fit(full_train_prep, y)\n",
    "    y_pred = est.predict_proba(full_train_prep)\n",
    "    list_y_pred.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_y_pred = np.asarray(list_y_pred, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_y_pred = list_y_pred.reshape(len(y), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_svc.fit(list_y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5661352041366589"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(stack_svc, list_y_pred, y, scoring='accuracy', cv=5, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# я попробовал разные классификаторы и чот значение не переходит 0.6 даже. мой терминатор из разных моделей не удался :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_clf = VotingClassifier([('rnf', rnf_clf), ('ext', ext_clf), ('svc', svc_clf), ('logic', logic_clf)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.645743798764973"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(vote_clf, full_train_prep, y, scoring='accuracy', cv=5, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.676091778882367"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logic_clf = LogisticRegression(solver='saga', penalty='l2', C=0.2, max_iter=500)\n",
    "logic_clf.fit(full_train_prep, y)\n",
    "np.mean(cross_val_score(logic_clf, full_train_prep, y, scoring='accuracy', cv=5, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попытка хорошая, но не превзошёл логистическую регрессию. Так к чему я это всё делал?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sand.jpg\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prep = logic_clf.predict(answer_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = y_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('end_answer.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  0.80368 результат, а прошлый 0.78732. Мне кажется, что можно каким-то образом поднять выше результат, если хорошо поработать на этапе подготовки данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_clf.fit(full_train_prep, y)\n",
    "y_prep = vote_clf.predict(answer_prep)\n",
    "submission['target'] = y_prep\n",
    "submission.to_csv('end_answer_vote.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попытка не пытка, подумал я и voting_classifier пустил на submission. 0.80981. Ура: Повышение на целых 0.6%. Правда жизни: То есть кроссвалидация не является показателем успешности на тесте..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"outstanding.jpg\" width=\"800\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
